{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project2-vgg.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pPiSYbarfVaN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wY0je3TWeBd",
        "colab_type": "text"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5trH6BqWWjvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhTP5NtXW-VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import codecs\n",
        "import copy\n",
        "import argparse\n",
        "import cv2\n",
        "import pandas\n",
        "import numpy as np\n",
        "import struct\n",
        "from PIL import Image\n",
        "from PIL import ImageFilter\n",
        "import pickle\n",
        "import zipfile\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, ZeroPadding2D, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOS4215AWm-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = './'\n",
        "extension = '.zip'\n",
        "\n",
        "for item in os.listdir(data_dir):\n",
        "  if item.endswith(extension):\n",
        "    file_name = os.path.abspath(item)\n",
        "    new_dir = file_name.replace('.zip', '')\n",
        "    \n",
        "    # print (file_name)\n",
        "    # print (new_dir)\n",
        "\n",
        "    zip_ref = zipfile.ZipFile(file_name)\n",
        "    zip_ref.extractall(new_dir)\n",
        "    zip_ref.close()\n",
        "    os.remove(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPiSYbarfVaN",
        "colab_type": "text"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKL2se5vfZHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReadData:\n",
        "  \n",
        "  def __init__(self, path, is_train=True, char_dict=None):\n",
        "    self.file_count = 0\n",
        "    self.is_train = is_train\n",
        "    self.iter_index = 0\n",
        "    self.path = path\n",
        "    self.char_dict = char_dict\n",
        "    self.use_filter = True\n",
        "    self.use_rotation = True\n",
        "  \n",
        "  # Read data\n",
        "\n",
        "  def read_one_file(self, f):\n",
        "    header_size = 10\n",
        "    while True:\n",
        "      header = np.fromfile(f, dtype='uint8', count=header_size)\n",
        "      if not header.size: break\n",
        "      sample_size = header[0] + (header[1]<<8) + (header[2]<<16) + (header[3]<<24)\n",
        "      tagcode = header[5] + (header[4]<<8)\n",
        "      width = header[6] + (header[7]<<8)\n",
        "      height = header[8] + (header[9]<<8)\n",
        "      if header_size + width*height != sample_size:\n",
        "        break\n",
        "      try:\n",
        "        image = np.fromfile(f, dtype='uint8', count=width*height).reshape((height,width))\n",
        "      except:\n",
        "        print (struct.pack('>H', tagcode).decode('gb2312'))\n",
        "      yield image, tagcode\n",
        "  \n",
        "  def read_from_dir(self, gnt_dir):\n",
        "    for file_name in os.listdir(gnt_dir):\n",
        "      if file_name.endswith('.gnt'):\n",
        "        file_path = os.path.join(gnt_dir, file_name)\n",
        "        with open(file_path, 'rb') as f:\n",
        "          for image, tagcode in read_one_file(f):\n",
        "            yield image, tagcode\n",
        "  \n",
        "  def read_one_gnt_file(self):\n",
        "    for file_name in os.listdir(self.path):\n",
        "      if file_name.endswith('.gnt'):\n",
        "        file_path = os.path.join(self.path, file_name)\n",
        "        with open(file_path, 'rb') as f:\n",
        "          x = []\n",
        "          y = []\n",
        "          for image, tagcode in self.read_one_file(f):\n",
        "            x.append(image)\n",
        "            y.append(tagcode)\n",
        "        yield x, y\n",
        "  \n",
        "  def load_next_file(self):\n",
        "    for x_one, y_one in self.read_one_gnt_file():\n",
        "      result_x = []\n",
        "      result_y = []\n",
        "      for i in range(len(x_one)):\n",
        "        result = self.read_convert_image(x_one[i])\n",
        "        result_x.append(result)\n",
        "        result_y.append(y_one[i])\n",
        "        if self.use_filter:\n",
        "          filtered_x = self.apply_filter(x_one[i])\n",
        "          result_x.append(filtered_x)\n",
        "          result_y.append(y_one[i])\n",
        "        if self.use_rotation:\n",
        "          rotated_x = self.rotate(x_one[i])\n",
        "          result_x.append(rotated_x)\n",
        "          result_y.append(y_one[i])\n",
        "      x = np.array(result_x)\n",
        "      y = np.array(result_y)\n",
        "      self.file_count += 1\n",
        "      print ('Loaded files ', self.file_count)\n",
        "      yield x, y\n",
        "  \n",
        "  def load_all(self):\n",
        "    x = []\n",
        "    y = []\n",
        "    for temp_x, temp_y in self.load_next_file():\n",
        "      x.extend(temp_x)\n",
        "      y.extend(temp_y)\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "  def rotate(self, image):\n",
        "    im = Image.fromarray(image)\n",
        "    im.rotate(random.randint(10,20))\n",
        "    im = im.resize([64, 64])\n",
        "    new_image = np.asarray(im)\n",
        "    new_image = new_image.reshape(new_image.shape[0], new_image.shape[1], 1)\n",
        "    return new_image\n",
        "  \n",
        "  def apply_filter(self,image):\n",
        "    im = Image.fromarray(image)\n",
        "    filters = [ImageFilter.BLUR, ImageFilter.CONTOUR, ImageFilter.EMBOSS]\n",
        "    im.filter(random.choice(filters))\n",
        "    im = im.resize([64, 64])\n",
        "    new_image = np.asarray(im)\n",
        "    new_image = new_image.reshape(new_image.shape[0], new_image.shape[1], 1)\n",
        "    return new_image\n",
        "  \n",
        "  def read_convert_image(self, image):\n",
        "    im = Image.fromarray(image)\n",
        "    im = im.resize([64, 64])\n",
        "    new_image = np.asarray(im)\n",
        "    new_image = new_image.reshape(new_image.shape[0], new_image.shape[1], 1)\n",
        "    return new_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZypplrvbgU91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GetCharList:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.train = ReadData('./HWDB1.1trn_gnt/', is_train=True)\n",
        "    self.test = ReadData('./HWDB1.1tst_gnt/', is_train=False)\n",
        "\n",
        "  def generate_char_list(self):\n",
        "    if os.path.isfile('char_list'):\n",
        "      with open('char_list', 'rb') as f:\n",
        "        char_list = pickle.load(f)\n",
        "        print ('Char list loaded')\n",
        "        return char_list\n",
        "    else:\n",
        "      char_list = []\n",
        "      for _, tagcode in self.train.read_from_dir(gnt_dir='./HWDB1.1trn_gnt/'):\n",
        "        char_list.append(tagcode)\n",
        "      with open('char_list', 'wb') as f:\n",
        "        pickle.dump(char_list, f)\n",
        "        print ('Char list generated')\n",
        "      return char_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZKmB0ZobH1b",
        "colab_type": "text"
      },
      "source": [
        "## VGG model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmNdiSAcD4qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convLayer(x, kHeight, kWidth, strideX, strideY,\n",
        "              featureNum, name, padding = \"SAME\"):\n",
        "  channel = int(x.get_shape()[-1])\n",
        "  with tf.variable_scope(name) as scope:\n",
        "    w = tf.get_variable(\"w\", shape = [kHeight, kWidth, channel, featureNum])\n",
        "    b = tf.get_variable(\"b\", shape = [featureNum])\n",
        "    featureMap = tf.nn.conv2d(x, w, strides = [1, strideY, strideX, 1], padding = padding)\n",
        "    out = tf.nn.bias_add(featureMap, b)\n",
        "    return tf.nn.relu(tf.reshape(out, featureMap.get_shape().as_list()), name = scope.name)\n",
        "\n",
        "def fcLayer(x, inputD, outputD, reluFlag, name):\n",
        "  # Fully connect layer\n",
        "  with tf.variable_scope(name) as scope:\n",
        "    w = tf.get_variable(\"w\", shape = [inputD, outputD], dtype = \"float\")\n",
        "    b = tf.get_variable(\"b\", [outputD], dtype = \"float\")\n",
        "    out = tf.nn.xw_plus_b(x, w, b, name = scope.name)\n",
        "    if reluFlag:\n",
        "      return tf.nn.relu(out)\n",
        "    else:\n",
        "      return out\n",
        "\n",
        "def maxPoolLayer(x, kHeight, kWidth, strideX, strideY, name, padding = \"SAME\"):\n",
        "  return tf.nn.max_pool(x, ksize = [1, kHeight, kWidth, 1],\n",
        "                        strides = [1, strideX, strideY, 1], \n",
        "                        padding = padding, name = name)\n",
        "\n",
        "def dropout(x, keepPro, name = None):\n",
        "  return tf.nn.dropout(x, keepPro, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYccScFDRRT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG19(object):\n",
        "  def __init__(self, x, keepPro, classNum, skip, modelPath = \"./vgg19.npy\"):\n",
        "    self.X = x\n",
        "    self.KEEPPRO = keepPro\n",
        "    self.CLASSNUM = classNum\n",
        "    self.SKIP = skip\n",
        "    self.MODELPATH = modelPath\n",
        "    self.build_model()\n",
        "\n",
        "  def build_model(self):\n",
        "    conv1_1 = convLayer(self.X, 3, 3, 1, 1, 128, \"conv1_1\" )\n",
        "    conv1_2 = convLayer(conv1_1, 3, 3, 1, 1, 128, \"conv1_2\")\n",
        "    pool1 = maxPoolLayer(conv1_2, 2, 2, 2, 2, \"pool1\")\n",
        "\n",
        "    conv2_1 = convLayer(pool1, 3, 3, 1, 1, 64, \"conv2_1\")\n",
        "    conv2_2 = convLayer(conv2_1, 3, 3, 1, 1, 64, \"conv2_2\")\n",
        "    pool2 = maxPoolLayer(conv2_2, 2, 2, 2, 2, \"pool2\")\n",
        "\n",
        "    conv3_1 = convLayer(pool2, 3, 3, 1, 1, 64, \"conv3_1\")\n",
        "    conv3_2 = convLayer(conv3_1, 3, 3, 1, 1, 64, \"conv3_2\")\n",
        "    conv3_3 = convLayer(conv3_2, 3, 3, 1, 1, 64, \"conv3_3\")\n",
        "    conv3_4 = convLayer(conv3_3, 3, 3, 1, 1, 64, \"conv3_4\")\n",
        "    pool3 = maxPoolLayer(conv3_4, 2, 2, 2, 2, \"pool3\")\n",
        "\n",
        "    conv4_1 = convLayer(pool3, 3, 3, 1, 1, 64, \"conv4_1\")\n",
        "    conv4_2 = convLayer(conv4_1, 3, 3, 1, 1, 64, \"conv4_2\")\n",
        "    conv4_3 = convLayer(conv4_2, 3, 3, 1, 1, 64, \"conv4_3\")\n",
        "    conv4_4 = convLayer(conv4_3, 3, 3, 1, 1, 64, \"conv4_4\")\n",
        "    pool4 = maxPoolLayer(conv4_4, 2, 2, 2, 2, \"pool4\")\n",
        "\n",
        "    conv5_1 = convLayer(pool4, 3, 3, 1, 1, 64, \"conv5_1\")\n",
        "    conv5_2 = convLayer(conv5_1, 3, 3, 1, 1, 64, \"conv5_2\")\n",
        "    conv5_3 = convLayer(conv5_2, 3, 3, 1, 1, 64, \"conv5_3\")\n",
        "    conv5_4 = convLayer(conv5_3, 3, 3, 1, 1, 64, \"conv5_4\")\n",
        "    pool5 = maxPoolLayer(conv5_4, 2, 2, 2, 2, \"pool5\")\n",
        "\n",
        "    fcIn = tf.reshape(pool5, [-1, 64*64*1])\n",
        "    fc6 = fcLayer(fcIn, 64*64*1, 4096, True, \"fc6\")\n",
        "    dropout1 = dropout(fc6, self.KEEPPRO)\n",
        "\n",
        "    fc7 = fcLayer(dropout1, 4096, 4096, True, \"fc7\")\n",
        "    dropout2 = dropout(fc7, self.KEEPPRO)\n",
        "\n",
        "    self.fc8 = fcLayer(dropout2, 4096, self.CLASSNUM, True, \"fc8\")\n",
        "\n",
        "  def load_model(self, sess):\n",
        "    wDict = np.load(self.MODELPATH, encoding = \"bytes\").item()\n",
        "    for name in wDict:\n",
        "      if name not in self.SKIP:\n",
        "        with tf.variable_scope(name, reuse = True):\n",
        "          for p in wDict[name]:\n",
        "            # Bias / weight\n",
        "            if len(p.shape) == 1:\n",
        "              sess.run(tf.get_variable('b', trainable = False).assign(p))\n",
        "            else:\n",
        "              sess.run(tf.get_variable('w', trainable = False).assign(p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1mDkuPgjYBH",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMwI-_iBjSiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize\n",
        "\n",
        "classNum = 3755\n",
        "skip = []\n",
        "chars = GetCharList()\n",
        "chars.test.use_rotation = False\n",
        "chars.test.use_filter = False\n",
        "\n",
        "with open('char_list', 'rb') as f:\n",
        "  char_list = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52iawFaNjbmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VGG19.build_model()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  model.load_model(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d2YeJHPjcRt",
        "colab_type": "text"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIa5RnAHjeDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}